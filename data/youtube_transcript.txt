our first story today is another cryptic tweet from Sam Alman now last time he made a cryptic tweet it was about 2 months out from the strawberry release this video is brought to you by vulture the easiest way to power your generative AI startup with the latest Nvidia chips check out vulture I&#39;ll drop a link in the description below this time he says I love being home in the midwest the night sky is so beautiful excited for the winter constellations to rise soon they are so great so from this there&#39;s already so much information to decrypt so first I love is his starting point now if we look back to his previous strawberry tweet I love all lowercase letters as well so following a very similar pattern as the last time that he gave hints for a new model or kind of a new tech coming from open AI now I love being home in the midwest the night&#39;s sky is so beautiful excited for the so winter constellations so constellation is likely in reference to the new Orion model which is rumored to be their next Frontier Model and it says winter so maybe we can expect it before the end of the year and then he says they are so great and somebody actually did the digging for us Orion is indeed one of the most prominent and easily recognizable winter constellations Orion Orion the model it&#39;s definitely coming soon next Microsoft is revamping their co-pilot product and to be honest it kind of needed a revamp the most compelling feature recall was indefinitely delayed for a while and then we just got information that might be released next month and that was really the only feature there was there was a dedicated co-pilot key which you could push and it would open up chat GPT natively in Windows but it wasn&#39;t much more than you were getting with chat GPT through the web so I&#39;m really glad to see Microsoft continuing to integrate AI into every aspect of Windows let&#39;s talk about all the features that are coming so this is co-pilot Pages let me show you what it does so this feels very similar to perplexity it&#39;s able to do web search it&#39;s able to reference external web pages so you know where they&#39;re coming from and it gives you an answer plus you can create a page from it this isn&#39;t anything that we haven&#39;t seen before but I think what&#39;s really unique is the interface from the AI creation you can start collaborating with anybody else on your team and you can continue using AI to iterate on this document so you could see somebody&#39;s typing right there create a proposal outline as a table for a sales opportunity using the same structure so yeah it&#39;s a really deeply integrated AI work product and it&#39;s cool I like it a lot so here is co-pilot in Excel now so you have a spreadsheet like normal but now you have this co-pilot window on the right side it writes python code for you it automatically outputs it in the Excel document just really really cool so you simply just like always type in natural language exactly what you want and copilot will create it for you in Excel and there it goes lots of different charts and again you don&#39;t have to specify exactly what you want to see in the chart you specify what you&#39;re trying to to accomplish with the output and here&#39;s the python code that was written to create those charts so again super impressive love to see it next here&#39;s co-pilot in PowerPoint so probably going to be the same thing you type in exactly what you want to see and it will create the deck for you why commercial EV charging stations would be valuable for a reail company including how it will help attract customers and increase foot traffic it&#39;s doing all the research for you puts together the deck you can reconfigure it any way you want you can add things and look at that just with a simple prompt and a click of a button you get the entire deck created for you and next here&#39;s co-pilot in Outlook so it&#39;s giving you what seems to be little tips of how to follow up it&#39;s giving you a summary at the top again not something super revolutionary but cool nonetheless but what I really want to show you is co-pilot Studio agent Builder let&#39;s see what the agents look like in Microsoft so here&#39;s co-pilot Studio this is a field service agent this feels very very much like custom gpts so not full agents like we&#39;ve built with other agentic Frameworks this seems very much like a reskin of custom gpts which is fine I love custom gpts so you can link to specific documents you need you can give it web search ability here you can actually let it see your documents internally which is really nice but yeah it&#39;s basically custom gpts and satian Adella commented on it and usually I wouldn&#39;t just cover a single comment but it&#39;s actually extremely telling and kind of a dig towards open AI as AI becomes more capable and agentic models themselves become more of a commodity and all value gets created by how you steer ground and fine-tune these models with your business data and workflow and how they compose with the UI layer of human to AI to human interaction this is something I&#39;ve talked about at length on this channel models are becoming a commodity they&#39;re already a commodity especially when llama was released and was essentially able to match the performance of the top closed sour Frontier models and SAA I&#39;ve said it before he&#39;s playing 4D chess he is investing in every AI company he is not putting all his chips into open ai&#39;s model he has partnered with meta on llama he&#39;s done so much I&#39;m just super impressed with how Allin he is on AI so congrats to Microsoft on all their launches next speaking of meta and llama it turns out Mark Zuckerberg may not have been telling the truth about llama not or never being trained on your Facebook data The Verge published this article last week meta fed its AI on almost everything you&#39;ve posted publicly since 2007 unless you&#39;re in the EU there&#39;s no ability to opt out of AI training settings that keep Facebook or Instagram post public now maybe what Mark Zuckerberg really meant is he&#39;s not going to train it on private data but if you&#39;ve posted publicly then they have trained on your data which makes sense look that is their major differentiation from open AI from really any other AI company is the fact that they have all of this unique highquality data from their products meta has acknowledged that all text and photos that adult Facebook and Instagram users have publicly published since 2007 have been fed into its artificial intelligence models Australia&#39;s ABC news reports that meta&#39;s Global privacy director Melinda claya initially rejected claims about user data from 2007 being leveraged for AI training during a local government inquiry about AI adoption before relenting after additional questions quote the truth of the matter is that unless you have consciously set those posts to private since 2007 meta has just decided that you will scrape all of the photos and all of the texts from every public post on Instagram or Facebook since 2007 unless there was a conscious decision to set them private that&#39;s the reality isn&#39;t it and she says correct and it should have been clear that they were going to do this because in their privacy Center they essentially just say it we use public posts and comments on Facebook and Instagram to train generative AI models for these features and for the open source Community we don&#39;t use posts or comments with an audience other than public for these purposes so I definitely remember Mark Zuckerberg saying that they&#39;re not training on Facebook&#39;s data but maybe he said private data and I just didn&#39;t notice so if you&#39;re on Facebook your data is getting trained on if your content is public next mraw AI has released a new model and in very mraw form all they did was drop a torrent link and everybody had to figure out out what it was and it turns out it is a vision model it&#39;s called pixol 12b and it is a vision model you load it up with an image and you can ask anything about that image I&#39;ve been meeing to play around with it I haven&#39;t had a chance yet but if you want me to do a test of it let me know in the comments next a new open source project from a former open aai employee looks really cool William says I&#39;m excited to announce the future of prompt engineering E11 developed from ideas during my time at open AI E11 is a light functional LM programming Library automatic versioning and tracing Rich local OSS visualization tools multimodality native E11 is built out of frustration for Frameworks like Lang chain AI on three principles prompts are programs not strings prompts are parameters of machine learning models and every call to a language model is worth its weight in credits prompting should be readable and scientific so here&#39;s an example of how it works on the left side what you&#39;re seeing is essentially the same thing with Lang chain and with E11 we have just a few lines of code you specify the model and then you define functions for the prompt that you want to use so you define joke you return tell me a joke about and then you simply call the method prom engineering is an optimization process and E11 automatically versions and serializes them no custom IDE or editor required very cool and they have an open- Source UI that you can use so prompt engineering goes from a dark art to a science with the right tools E11 studio is a local open- Source tool for prompt Version Control monitoring and visualization so that&#39;s what we&#39;re seeing here and Version Control for prompts is incredibly important when you&#39;re building robust and really production ready systems using large language models especially when you&#39;re using an agentic framework this would plug in great into that and it&#39;s multimodal natively so you can see right here all the images are getting output so if you want to check it out I&#39;ll drop the GitHub Link in the description below if it is open source so enjoy next Adobe is coming out with their own textto video model and it is using the same brand name Firefly and Alexandre says welcome to the world Adobe Firefly video model announced today public beta later this year designed to be safe for commercial use and that&#39;s really the distinguishing property of adobe&#39;s AI Ventures is the fact that they&#39;re only training on what they say is IP that they either own or licensed for great cinematic quality and fluid motion camera controls and of course deep integration into our tools so here&#39;s an example of what it&#39;s going to look like you can upload an image you can have a prompt right here and it generates it so here&#39;s a few examples different prompts and the videos look pretty good not fantastic but pretty darn good and it feels very similar to the text to image product that they released earlier this year except it&#39;s text to video and here&#39;s one that I think is amazing so this one right here is real so it&#39;s a little girl with a magnifying glass looking at a flower and that&#39;s the reference video video and then this down here is the generated clip this is the clip based on what you may need to fill in your extra video that you may not have captured so I think this is absolutely brilliant it looks really good and if you forget to capture a shot or you just need something extra as you&#39;re thinking about it when you&#39;re editing now you can do it simply with a prompt next the CEO of Clara is basically rewriting their entire text stack themselves using Ai and I think this is extremely telling for the the future of SAS businesses SAS businesses have been overcharging for a lot of years in a former life I was a SAS startup founder so this is very familiar to me Clara CEO said that the company is shutting down its software as a service provider Salesforce and within a few weeks will shut down workday two of the biggest SAS companies on the planet there are large ongoing internal initiatives that are a combination of AI standardization and simplification as an example we just shut down Salesforce within a few weeks we will shut down workday we are shutting down a lot of our SAS providers as we are able to consolidate now I&#39;m a little bit torn on this on the one hand I totally understand you have all of these new tools that allow you to create software so much more efficiently and at such a higher rate that maybe you don&#39;t actually need to pay for all these software as of services which can be really expensive depending on how many employees you have but on the other hand engineers in general underestimate the amount of work it&#39;s going to take to build new systems and I think this is going to be an example of that at my previous company the hard part wasn&#39;t actually the core software that we were building it was things like Integrations into other platforms building those Integrations maintaining them making sure that we had all the right ones that takes a tremendous amount of work and I don&#39;t know if AI is quite there yet but it&#39;ll be interesting to see how AI affects the SAS industry next Google Labs releases notebook LM which is basically a way to load up not notes or documents and then it converts it into a podcast for you so you can actually listen to a discussion based on whatever you&#39;ve uploaded our new audio overview feature can turn documents slides charts and more into engaging discussions with one click so here&#39;s an example which is based on a blog post notebook LM goes Global with slide support and better ways to fact check you ever get that feeling like you&#39;re just drowning in information articles PDFs websites all promising to like unlock the secrets of the universe or at least help you finally finished that research project you&#39;ve been putting off exactly it&#39;s like trying to drink from a fire hose you know it sounds really good it&#39;s interesting I&#39;m trying to figure out what the actual use cases are I can imagine loading up a research paper and listening to it but I don&#39;t know is it going to be as effective as just reading it what do you think the use cases for this are it&#39;s definitely cool Tech but I&#39;m just not sure what the actual applications are next of course last week 01 was released by open AI it made all the head headlines I made multiple videos about it be sure to check those out and the Ark prize tested it as a reminder The Arc prize is a benchmark specific for AGI and many of the other benchmarks in the world have really just been beaten by artificial intelligence at this point but the arc prize is very unique in that if you&#39;re a human and you&#39;re looking at the test it&#39;s very simple to figure out but AI really struggles with it because Arc prizes test test specifically for the ability to acquire new knowledge and then use that new knowledge in figuring out how to solve these puzzles and 01 did pretty well but it seems like just testing a model is not enough and I&#39;m going to talk about what that actually means so here we can see an 8% score for Gemini 1.5 a 9% score for GPT 40 and here&#39;s a 133% score for 01 mini and 01 preview and Sonic 3.5 are tied at 21% now 21% doesn&#39;t sound all that great but just as a reference 21% compared to GPT 40&#39;s 9% is a massive massive Improvement now all these other companies have done much better mine&#39;s AI for example and they&#39;re using different techniques not just the raw model but they&#39;re using fine tuning and they&#39;re using different agentic Frameworks and so now what I&#39;m thinking is a company like mine&#39;s AI is going to take 01 plug it into their existing framework for how they accomplish a 46% and then get a much higher score so again it&#39;s not enough for just the raw model right now next we have another glimpse into the future of video games tensent presents game gen o open world video game generation look at this video [Music] so we have a paper and we have a GitHub page for it so we introduced game gen o the first diffusion Transformer model tailored for the generation of open world video games highquality open domain Generation by simulating a wide array of game engine features such as Innovative character Dynamic environments complex actions and diverse events now just a couple weeks ago I covered Doom being created exclusively by a diffusion model and now we have this so if you don&#39;t think video games are going to be vastly different in just a few years you are going to be very surprised let&#39;s look at a few examples of the actual Generations themselves here are character generations geralt of Rivia here&#39;s one that looks very similar to Red Dead Redemption here&#39;s one that&#39;s a security guard kind of looks like snake from Metal Gear Solid they also have environment generation so here&#39;s beautiful cherry blossoms here are some palm trees here&#39;s a pyramid and it could also generate action scenes so here&#39;s one driving here&#39;s one flying sailing here&#39;s a motorcycle looks really really good and here are characters walking through what looks to be any modern video game so here&#39;s a cyber Punk version and something that kind of looks like Destiny so another really cool project showing what the future video games are going to be like and for the last story of today the Godmother of AI launches a new company F Lee has launched World Labs with $230 million of funding at a billion dollar valuation the company&#39;s Focus will be on developing artificial intelligence with 3D perception World Labs describes its primary product as large World models in a blog post announcing the company&#39;s launch it pointed out that current generative AI models can only interact with the world through text audio and video This is something that Yan laon has talked extensively about and why he doesn&#39;t think large language models are enough to actually model the world but that is what they&#39;re hoping to do here spatial artificial intelligence to advance beyond the capabilities of today&#39;s models we need spatially intelligent AI that can model the world and reason about objects places and interactions in 3D space and time now the other company that is doing this or at least has the data to go do this is Tesla they have a ton of real world video data that can be used to train World models so I&#39;m really curious what they&#39;re going to come out with soon so that&#39;s it for today if you enjoyed this video please consider giving a like And subscribe and I&#39;ll see you in the next one 

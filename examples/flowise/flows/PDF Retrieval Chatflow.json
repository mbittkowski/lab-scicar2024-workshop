{
  "nodes": [
    {
      "id": "pdfFile_0",
      "position": {
        "x": -714.8709516438829,
        "y": 165.80693653050963
      },
      "type": "customNode",
      "data": {
        "id": "pdfFile_0",
        "label": "Pdf File",
        "version": 1,
        "name": "pdfFile",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from PDF files",
        "inputParams": [
          {
            "label": "Pdf File",
            "name": "pdfFile",
            "type": "file",
            "fileType": ".pdf",
            "id": "pdfFile_0-input-pdfFile-file"
          },
          {
            "label": "Usage",
            "name": "usage",
            "type": "options",
            "options": [
              {
                "label": "One document per page",
                "name": "perPage"
              },
              {
                "label": "One document per file",
                "name": "perFile"
              }
            ],
            "default": "perPage",
            "id": "pdfFile_0-input-usage-options"
          },
          {
            "label": "Use Legacy Build",
            "name": "legacyBuild",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_0-input-legacyBuild-boolean"
          },
          {
            "label": "Additional Metadata",
            "name": "metadata",
            "type": "json",
            "description": "Additional metadata to be added to the extracted documents",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_0-input-metadata-json"
          },
          {
            "label": "Omit Metadata Keys",
            "name": "omitMetadataKeys",
            "type": "string",
            "rows": 4,
            "description": "Each document loader comes with a default set of metadata keys that are extracted from the document. You can use this field to omit some of the default metadata keys. The value should be a list of keys, seperated by comma. Use * to omit all metadata keys execept the ones you specify in the Additional Metadata field",
            "placeholder": "key1, key2, key3.nestedKey1",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_0-input-omitMetadataKeys-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "pdfFile_0-input-textSplitter-TextSplitter"
          }
        ],
        "inputs": {
          "textSplitter": "{{tokenTextSplitter_0.data.instance}}",
          "usage": "perFile",
          "legacyBuild": "",
          "metadata": "",
          "omitMetadataKeys": ""
        },
        "outputAnchors": [
          {
            "id": "pdfFile_0-output-pdfFile-Document",
            "name": "pdfFile",
            "label": "Document",
            "description": "Load data from PDF files",
            "type": "Document"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 509,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -714.8709516438829,
        "y": 165.80693653050963
      }
    },
    {
      "id": "tokenTextSplitter_0",
      "position": {
        "x": -1161.0679870707795,
        "y": 383.76386451219537
      },
      "type": "customNode",
      "data": {
        "id": "tokenTextSplitter_0",
        "label": "Token Text Splitter",
        "version": 1,
        "name": "tokenTextSplitter",
        "type": "TokenTextSplitter",
        "baseClasses": [
          "TokenTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Splits a raw text string by first converting the text into BPE tokens, then split these tokens into chunks and convert the tokens within a single chunk back into text.",
        "inputParams": [
          {
            "label": "Encoding Name",
            "name": "encodingName",
            "type": "options",
            "options": [
              {
                "label": "gpt2",
                "name": "gpt2"
              },
              {
                "label": "r50k_base",
                "name": "r50k_base"
              },
              {
                "label": "p50k_base",
                "name": "p50k_base"
              },
              {
                "label": "p50k_edit",
                "name": "p50k_edit"
              },
              {
                "label": "cl100k_base",
                "name": "cl100k_base"
              }
            ],
            "default": "gpt2",
            "id": "tokenTextSplitter_0-input-encodingName-options"
          },
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "description": "Number of characters in each chunk. Default is 1000.",
            "default": 1000,
            "optional": true,
            "id": "tokenTextSplitter_0-input-chunkSize-number"
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "description": "Number of characters to overlap between chunks. Default is 200.",
            "default": 200,
            "optional": true,
            "id": "tokenTextSplitter_0-input-chunkOverlap-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "encodingName": "gpt2",
          "chunkSize": 1000,
          "chunkOverlap": 200
        },
        "outputAnchors": [
          {
            "id": "tokenTextSplitter_0-output-tokenTextSplitter-TokenTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "tokenTextSplitter",
            "label": "TokenTextSplitter",
            "description": "Splits a raw text string by first converting the text into BPE tokens, then split these tokens into chunks and convert the tokens within a single chunk back into text.",
            "type": "TokenTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 473,
      "selected": false,
      "positionAbsolute": {
        "x": -1161.0679870707795,
        "y": 383.76386451219537
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": -304.3429218886183,
        "y": -415.11589363573296
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 7,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-3.5-turbo",
            "id": "chatOpenAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string"
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, Conversational Agent, Tool Agent",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-imageResolution-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o-mini",
          "temperature": "0.0",
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 670,
      "selected": false,
      "positionAbsolute": {
        "x": -304.3429218886183,
        "y": -415.11589363573296
      },
      "dragging": false
    },
    {
      "id": "retrievalQAChain_0",
      "position": {
        "x": 195.18218753286533,
        "y": 428.34163704279365
      },
      "type": "customNode",
      "data": {
        "id": "retrievalQAChain_0",
        "label": "Retrieval QA Chain",
        "version": 2,
        "name": "retrievalQAChain",
        "type": "RetrievalQAChain",
        "baseClasses": [
          "RetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "QA chain to answer a question based on the retrieved documents",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "retrievalQAChain_0-input-model-BaseLanguageModel"
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "retrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "retrievalQAChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatOpenAI_0.data.instance}}",
          "vectorStoreRetriever": "{{memoryVectorStore_0.data.instance}}",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "retrievalQAChain_0-output-retrievalQAChain-RetrievalQAChain|BaseChain|Runnable",
            "name": "retrievalQAChain",
            "label": "RetrievalQAChain",
            "description": "QA chain to answer a question based on the retrieved documents",
            "type": "RetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 332,
      "selected": false,
      "positionAbsolute": {
        "x": 195.18218753286533,
        "y": 428.34163704279365
      },
      "dragging": false
    },
    {
      "id": "memoryVectorStore_0",
      "position": {
        "x": -291.8854668788134,
        "y": 423.8058754799006
      },
      "type": "customNode",
      "data": {
        "id": "memoryVectorStore_0",
        "label": "In-Memory Vector Store",
        "version": 1,
        "name": "memoryVectorStore",
        "type": "Memory",
        "baseClasses": [
          "Memory",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.",
        "inputParams": [
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "optional": true,
            "id": "memoryVectorStore_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "memoryVectorStore_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "memoryVectorStore_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "document": [
            "{{pdfFile_0.data.instance}}"
          ],
          "embeddings": "{{openAIEmbeddings_0.data.instance}}",
          "topK": "4"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Memory Retriever",
                "description": "",
                "type": "Memory | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "memoryVectorStore_0-output-vectorStore-Memory|VectorStore",
                "name": "vectorStore",
                "label": "Memory Vector Store",
                "description": "",
                "type": "Memory | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 407,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -291.8854668788134,
        "y": 423.8058754799006
      }
    },
    {
      "id": "openAIEmbeddings_0",
      "position": {
        "x": -669.3801804370908,
        "y": 728.7793353194193
      },
      "type": "customNode",
      "data": {
        "id": "openAIEmbeddings_0",
        "label": "OpenAI Embeddings",
        "version": 4,
        "name": "openAIEmbeddings",
        "type": "OpenAIEmbeddings",
        "baseClasses": [
          "OpenAIEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "OpenAI API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "openAIEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "text-embedding-ada-002",
            "id": "openAIEmbeddings_0-input-modelName-asyncOptions"
          },
          {
            "label": "Strip New Lines",
            "name": "stripNewLines",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-stripNewLines-boolean"
          },
          {
            "label": "Batch Size",
            "name": "batchSize",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-batchSize-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-basepath-string"
          },
          {
            "label": "Dimensions",
            "name": "dimensions",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-dimensions-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "text-embedding-3-small",
          "stripNewLines": "",
          "batchSize": "",
          "timeout": "",
          "basepath": "",
          "dimensions": ""
        },
        "outputAnchors": [
          {
            "id": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "name": "openAIEmbeddings",
            "label": "OpenAIEmbeddings",
            "description": "OpenAI API to generate embeddings for a given text",
            "type": "OpenAIEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 424,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -669.3801804370908,
        "y": 728.7793353194193
      }
    },
    {
      "id": "stickyNote_0",
      "position": {
        "x": 419.40490493470355,
        "y": -35.17832167629382
      },
      "type": "stickyNote",
      "data": {
        "id": "stickyNote_0",
        "label": "Sticky Note",
        "version": 2,
        "name": "stickyNote",
        "type": "StickyNote",
        "baseClasses": [
          "StickyNote"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Add a sticky note",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNote_0-input-note-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "Prompt:\nLese die Rechnung aufmerksam und vollständig!\nExtrahiere die Daten für den Abfahrtsort, den Zielort und den bezahlten Betrag inklusive Mehrwertsteuer.\nGebe ein JSON-Objekt mit folgender Struktur zurück: {\n\"abfahrtsort\": Abfahrtsort,\n\"zielort\": Zielort,\n\"preis\": Bezahlter Betrag inklusive Mehrwertsteuer\n}"
        },
        "outputAnchors": [
          {
            "id": "stickyNote_0-output-stickyNote-StickyNote",
            "name": "stickyNote",
            "label": "StickyNote",
            "description": "Add a sticky note",
            "type": "StickyNote"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 284,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 419.40490493470355,
        "y": -35.17832167629382
      }
    }
  ],
  "edges": [
    {
      "source": "tokenTextSplitter_0",
      "sourceHandle": "tokenTextSplitter_0-output-tokenTextSplitter-TokenTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "pdfFile_0",
      "targetHandle": "pdfFile_0-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "tokenTextSplitter_0-tokenTextSplitter_0-output-tokenTextSplitter-TokenTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-pdfFile_0-pdfFile_0-input-textSplitter-TextSplitter"
    },
    {
      "source": "pdfFile_0",
      "sourceHandle": "pdfFile_0-output-pdfFile-Document",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-document-Document",
      "type": "buttonedge",
      "id": "pdfFile_0-pdfFile_0-output-pdfFile-Document-memoryVectorStore_0-memoryVectorStore_0-input-document-Document"
    },
    {
      "source": "openAIEmbeddings_0",
      "sourceHandle": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "openAIEmbeddings_0-openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-memoryVectorStore_0-memoryVectorStore_0-input-embeddings-Embeddings"
    },
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "retrievalQAChain_0",
      "targetHandle": "retrievalQAChain_0-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-retrievalQAChain_0-retrievalQAChain_0-input-model-BaseLanguageModel"
    },
    {
      "source": "memoryVectorStore_0",
      "sourceHandle": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
      "target": "retrievalQAChain_0",
      "targetHandle": "retrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "memoryVectorStore_0-memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever-retrievalQAChain_0-retrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    }
  ]
}